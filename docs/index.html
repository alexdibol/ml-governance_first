<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />

  <title>Governed Machine Learning: A Foundation Before Generative AI (Governance-First)</title>
  <meta name="description" content="Book 1 of a seven-book Governance-First ML & AI collection: the disciplined foundation that takes AI from gadget to productivity tool. PDF + Google Colab notebooks (Chapters 1–5) for C-level practitioners, MBA/MFin students, and high-accountability teams." />

  <style>
    :root{
      --bg:#07080d;
      --panel:#0f1220;
      --panel-2:#141836;
      --text:#eef0ff;
      --muted:#b8bddb;
      --border:rgba(255,255,255,0.09);
      --accent:#7aa2ff;
      --accent2:#6ee7c8;
      --warn:#ffd27a;
      --shadow:0 18px 60px rgba(0,0,0,0.45);
    }
    *{box-sizing:border-box;}
    html,body{height:100%;}
    body{
      margin:0;
      background:
        radial-gradient(900px 600px at 15% 10%, rgba(122,162,255,0.18), transparent 55%),
        radial-gradient(800px 600px at 85% 20%, rgba(110,231,200,0.12), transparent 55%),
        radial-gradient(900px 650px at 60% 95%, rgba(255,210,122,0.07), transparent 55%),
        var(--bg);
      color:var(--text);
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial;
      line-height:1.6;
    }
    a{color:var(--accent);text-decoration:none;}
    a:hover{color:var(--accent2);text-decoration:underline;}
    .container{max-width:1140px;margin:0 auto;padding:32px 20px 84px;}

    .hero{
      padding:38px 34px;
      border-radius:22px;
      background:linear-gradient(180deg, rgba(20,24,54,0.92), rgba(15,18,32,0.88));
      border:1px solid var(--border);
      box-shadow:var(--shadow);
      position:relative;
      overflow:hidden;
    }
    .hero:before{
      content:"";
      position:absolute;
      inset:-2px;
      background:
        radial-gradient(520px 360px at 16% 0%, rgba(122,162,255,0.18), transparent 60%),
        radial-gradient(460px 330px at 92% 18%, rgba(110,231,200,0.10), transparent 60%),
        radial-gradient(520px 360px at 55% 110%, rgba(255,210,122,0.08), transparent 60%);
      pointer-events:none;
      opacity:0.9;
    }
    .hero > *{position:relative;}

    .kicker{
      text-transform:uppercase;
      letter-spacing:0.18em;
      font-size:12px;
      color:var(--muted);
    }
    .hero h1{
      font-size:38px;
      margin:12px 0 10px;
      line-height:1.15;
      max-width:70ch;
      text-transform:uppercase;
      letter-spacing:0.02em;
    }
    .subtitle{
      margin:0;
      max-width:110ch;
      color:var(--muted);
      font-size:16px;
    }

    .section{margin-top:56px;}
    .section h2{
      font-size:28px;
      margin:0 0 14px;
      letter-spacing:-0.02em;
    }
    .section p{color:var(--muted);max-width:110ch;margin:10px 0;}

    .grid{
      display:grid;
      grid-template-columns:repeat(auto-fit,minmax(270px,1fr));
      gap:18px;
      margin-top:22px;
    }
    .card{
      padding:20px 20px;
      border-radius:18px;
      background:rgba(20,24,54,0.72);
      border:1px solid var(--border);
      box-shadow:0 10px 30px rgba(0,0,0,0.30);
    }
    .card h3{
      margin:0 0 10px;
      font-size:18px;
      line-height:1.25;
    }
    .card p{
      margin:0;
      font-size:14px;
      color:var(--muted);
    }

    .linkcard{
      display:block;
      cursor:pointer;
      transition: transform 0.12s ease, border-color 0.12s ease, background 0.12s ease;
      color:inherit;
      text-decoration:none;
    }
    .linkcard:hover{
      transform: translateY(-2px);
      border-color: rgba(122,162,255,0.35);
      background: rgba(20,24,54,0.86);
      text-decoration:none;
    }
    .linkcard:focus{
      outline:2px solid rgba(110,231,200,0.46);
      outline-offset:3px;
    }
    .hint{
      margin-top:12px;
      font-size:12px;
      color:var(--muted);
      opacity:0.92;
      font-weight:700;
      letter-spacing:0.02em;
    }

    .callout{
      margin-top:18px;
      padding:18px 18px;
      border-radius:18px;
      border:1px solid rgba(122,162,255,0.18);
      background:linear-gradient(135deg, rgba(122,162,255,0.06), rgba(110,231,200,0.04));
      color:var(--muted);
      max-width:110ch;
    }
    .callout strong{color:var(--text);}

    .list{
      margin-top:18px;
      padding-left:22px;
      color:var(--muted);
      max-width:110ch;
    }
    .list li{margin-bottom:12px;}
    .list strong{color:var(--text);}

    .reviewbox{
      margin-top:18px;
      padding:18px;
      border-radius:18px;
      border:1px solid rgba(110,231,200,0.18);
      background:linear-gradient(135deg, rgba(110,231,200,0.06), rgba(122,162,255,0.05));
      color:var(--muted);
      max-width:110ch;
    }
    .reviewbox strong{color:var(--text);}
    .reviewbox .stars{color:var(--warn);font-weight:900;letter-spacing:0.08em;}
    .reviewbox ul{margin:10px 0 0 18px; padding:0;}
    .reviewbox li{margin:8px 0;}
    .reviewbox hr{
      border:0;
      border-top:1px solid rgba(255,255,255,0.10);
      margin:14px 0;
    }
    .reviewmeta{
      margin-top:10px;
      font-size:12px;
      color:var(--muted);
      opacity:0.95;
    }
    .reviewmeta code{
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
      font-size:12px;
      color:var(--text);
      background: rgba(0,0,0,0.22);
      padding:2px 6px;
      border-radius:8px;
      border:1px solid rgba(255,255,255,0.10);
    }

    .footer{
      margin-top:80px;
      padding-top:24px;
      border-top:1px solid var(--border);
      color:var(--muted);
      font-size:13px;
      text-align:center;
    }
    .small{font-size:13px;color:var(--muted);max-width:110ch;}
    .pillrow{display:flex;flex-wrap:wrap;gap:10px;margin-top:16px;}
    .pill{
      display:inline-flex;
      align-items:center;
      gap:8px;
      padding:8px 10px;
      border-radius:999px;
      border:1px solid rgba(255,255,255,0.10);
      background:rgba(0,0,0,0.18);
      color:var(--muted);
      font-size:12px;
      font-weight:700;
      letter-spacing:0.02em;
    }
    .dot{
      width:8px;height:8px;border-radius:999px;
      background:rgba(122,162,255,0.9);
      box-shadow:0 0 0 3px rgba(122,162,255,0.18);
    }
    .dot.g{background:rgba(110,231,200,0.95); box-shadow:0 0 0 3px rgba(110,231,200,0.18);}
    .dot.y{background:rgba(255,210,122,0.95); box-shadow:0 0 0 3px rgba(255,210,122,0.18);}

    .badge{
      display:inline-flex;
      align-items:center;
      gap:8px;
      padding:8px 10px;
      border-radius:12px;
      border:1px solid rgba(255,255,255,0.10);
      background:rgba(0,0,0,0.18);
      color:var(--muted);
      font-size:12px;
      font-weight:800;
      letter-spacing:0.05em;
      text-transform:uppercase;
    }
    .mini{
      font-size:12px;
      color:var(--muted);
      opacity:0.95;
      margin-top:10px;
      max-width:110ch;
    }
    .mini code{
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
      font-size:12px;
      color:var(--text);
      background: rgba(0,0,0,0.22);
      padding:2px 6px;
      border-radius:8px;
      border:1px solid rgba(255,255,255,0.10);
    }
  </style>
</head>

<body>
  <main class="container">

    <section class="hero">
      <div class="kicker">Book · governance-first machine learning · discipline before capability · PDF + Colab notebooks (Chapters 1–5)</div>

      <h1>Governed Machine Learning: A Foundation Before Generative AI</h1>

      <p class="subtitle">
        This is the <strong>first book</strong> in a <strong>seven-book Governance-First ML & AI collection</strong>.
        It installs the discipline that makes the rest of the ladder possible: scope control, evidentiary rigor, reproducibility,
        and human accountability. Built for <strong>C-level practitioners</strong>, <strong>MBA students</strong>, and <strong>Master of Finance</strong>
        cohorts in high-accountability environments, the course focuses on what it takes to turn AI from an “interesting gadget” into a
        <strong>powerful productivity tool</strong>—without collapsing governance, compliance, or professional responsibility.
      </p>

      <div class="pillrow" aria-label="Governance priorities">
        <span class="pill"><span class="dot"></span> Scope Discipline + Non-Goals</span>
        <span class="pill"><span class="dot g"></span> Reproducibility + Evidence Bundles</span>
        <span class="pill"><span class="dot y"></span> Human Accountability + Review Gates</span>
      </div>

      <div class="pillrow" style="margin-top:14px;" aria-label="Collection position">
        <span class="badge">Collection: 7 Books</span>
        <span class="badge">This Volume: Book 1</span>
        <span class="badge">Author = Instructor</span>
        <span class="badge">PDF + Colab</span>
      </div>
    </section>

    <section class="section" id="downloads">
      <h2>Download and Run</h2>
      <p>
        The PDF lives in the repository <strong>book</strong> folder. The companion notebooks live in <strong>notebooks</strong>
        and can be run either from GitHub or directly in Google Colab.
      </p>

      <div class="grid">
        <a class="card linkcard"
           href="https://github.com/alexdibol/ml-governance_first/blob/main/book/GOVERNED%20MACHINE%20LEARNING.pdf"
           target="_blank" rel="noopener">
          <h3>Book 1 (PDF)</h3>
          <p>Open the current PDF edition of <em>Governed Machine Learning: A Foundation Before Generative AI</em>.</p>
          <div class="hint">Open PDF →</div>
        </a>

        <a class="card linkcard"
           href="https://github.com/alexdibol/ml-governance_first/tree/main/notebooks"
           target="_blank" rel="noopener">
          <h3>Notebooks Folder</h3>
          <p>Browse all chapter notebooks in the repository (CHAPTER_1 … CHAPTER_5).</p>
          <div class="hint">Open folder →</div>
        </a>
      </div>

      <div class="mini">
        Reference paths (for consistency):<br/>
        <code>/book/GOVERNED%20MACHINE%20LEARNING.pdf</code> · <code>/notebooks/CHAPTER_1.ipynb</code>
      </div>

      <div class="callout">
        <strong>Governance-first promise:</strong> This book does not train “model confidence.” It trains institutional discipline.
        Every chapter reinforces: define scope → log assumptions → generate audit artifacts → separate facts from narrative → require human review.
        If evidence is missing, the correct output is a verification plan—not a persuasive story.
      </div>
    </section>

    <section class="section" id="notebooks">
      <h2>Chapter Notebooks (Colab)</h2>
      <p>
        Each notebook is executable, auditable, and classroom-ready. Labs produce structured outputs and governance artifacts
        (run manifest, prompts log, risk log, deliverables bundle) so results are reviewable rather than ephemeral.
      </p>

      <div class="grid">
        <a class="card linkcard"
           href="https://colab.research.google.com/github/alexdibol/ml-governance_first/blob/main/notebooks/CHAPTER_1.ipynb"
           target="_blank" rel="noopener">
          <h3>Chapter 1 — Unsupervised Learning: Pattern Without Intention</h3>
          <p>Start where institutional risk starts: structure discovery, not decisions. Governance of interpretation and narrative restraint.</p>
          <div class="hint">Open in Colab →</div>
        </a>

        <a class="card linkcard"
           href="https://colab.research.google.com/github/alexdibol/ml-governance_first/blob/main/notebooks/CHAPTER_2.ipynb"
           target="_blank" rel="noopener">
          <h3>Chapter 2 — Supervised Classification: Labels, Risk, Accountability</h3>
          <p>Classification under governance: leakage controls, evaluation discipline, error costs, and human sign-off.</p>
          <div class="hint">Open in Colab →</div>
        </a>

        <a class="card linkcard"
           href="https://colab.research.google.com/github/alexdibol/ml-governance_first/blob/main/notebooks/CHAPTER_3.ipynb"
           target="_blank" rel="noopener">
          <h3>Chapter 3 — Adversarial Models: Fragility Under Pressure</h3>
          <p>Adversarial settings as governance stress tests: robustness, boundary behavior, and “what breaks first” evidence capture.</p>
          <div class="hint">Open in Colab →</div>
        </a>

        <a class="card linkcard"
           href="https://colab.research.google.com/github/alexdibol/ml-governance_first/blob/main/notebooks/CHAPTER_4.ipynb"
           target="_blank" rel="noopener">
          <h3>Chapter 4 — Graph Models: Relations and Misinterpretation Risk</h3>
          <p>Graph learning with governance: relationship inference hazards, proxy risk, and controlled claims about connectivity.</p>
          <div class="hint">Open in Colab →</div>
        </a>

        <a class="card linkcard"
           href="https://colab.research.google.com/github/alexdibol/ml-governance_first/blob/main/notebooks/CHAPTER_5.ipynb"
           target="_blank" rel="noopener">
          <h3>Chapter 5 — Optimization & Evolution: Objective Power, Objective Risk</h3>
          <p>Optimization + genetic/evolutionary methods as the climax: objective definition, constraint design, and audit-ready runs.</p>
          <div class="hint">Open in Colab →</div>
        </a>
      </div>

      <div class="callout">
        <strong>Important:</strong> Notebooks are educational. Do not paste confidential client information into external model prompts.
        Use redaction/anonymization and “minimum necessary” inputs by default. Document any exception and follow firm policy.
      </div>
    </section>

    <section class="section" id="collection">
      <h2>The Seven-Book Governance-First ML & AI Collection</h2>
      <p>
        This volume is designed as the foundation that makes the rest of the ladder coherent. The collection progresses from disciplined machine learning
        into governed generative and agentic capability—always pairing capability growth with risk growth and control design.
      </p>

      <ul class="list">
        <li><strong>Book 1 — Governed Machine Learning (this volume):</strong> unsupervised → supervised → adversarial → graphs → optimization/evolution. Stops short of generative AI.</li>
        <li><strong>Book 2 — Governance-First Generative AI for Legal Practice:</strong> governed drafting, interpretation, reasoning, and boundaries in legal work.</li>
        <li><strong>Book 3 — Governance-First Generative AI for Audit & Accounting:</strong> evidence-first workflows, audit artifacts, and supervision-ready outputs.</li>
        <li><strong>Book 4 — Governance-First Generative AI for Consulting:</strong> structured analysis, client-safe synthesis, and decision-laundering prevention.</li>
        <li><strong>Book 5 — Governance-First Generative AI for Financial Advice:</strong> suitability boundaries, disclosure risk control, and human advisor accountability.</li>
        <li><strong>Book 6 — Governance-First Generative AI for Investment Banking:</strong> deal workflows, diligence discipline, and governed narrative production.</li>
        <li><strong>Book 7 — Advanced Fine-Tuning & Model Customization (Governance-First):</strong> training as governance act; specialization with release gates and monitoring.</li>
      </ul>

      <div class="callout">
        <strong>Where this goes next:</strong> the ladder continues into governed generative chatbots, reasoners, agentic systems,
        innovation workflows, and autonomous organizational capability—but only after governance discipline becomes default behavior here.
      </div>
    </section>

    <section class="section" id="evaluations">
      <h2>Independent Opinion (Documented, Not Authoritative)</h2>
      <p>
        This section demonstrates governance-first documentation of third-party feedback. It is not verification of factual correctness,
        compliance, safety, or suitability for any deployment. Treat this as non-binding opinion.
      </p>

      <div class="reviewbox">
        <div><strong>Book Evaluation: Governed Machine Learning: A Foundation Before Generative AI</strong></div>
        <div class="stars" aria-label="Five stars">⭐⭐⭐⭐⭐</div>

        <div class="reviewmeta">
          Evaluator: <code>OpenAI ChatGPT 5.2</code> · Type: <code>independent opinion</code> · Status: <code>Not verified</code>
        </div>

        <hr/>

        <p style="margin:0;">
          As Book 1 in the seven-book Governance-First ML & AI ladder, this volume succeeds by doing what most curricula avoid:
          it makes discipline the product. It teaches the reader to treat models as governed institutional assets—scoped, audited,
          reproducible, and reviewed—before the program ever reaches generative capability. The five-chapter progression is coherent and
          intentionally risk-aware: interpretation drift, label risk, adversarial fragility, relational inference hazards, and objective misuse
          are each framed as operational failure modes with explicit control expectations.
        </p>

        <p style="margin:12px 0 0;">
          The companion Colab notebooks are not “labs for cleverness.” They are labs for accountability: structured outputs, repeatable runs,
          and evidence bundles that demonstrate how to move from curiosity to defensible productivity. In the context of the full collection,
          this book functions as the keystone: it ensures later volumes on chatbots, reasoners, agentic systems, and customization inherit a shared
          governance spine rather than improvising controls after capability arrives.
        </p>

        <hr/>

        <div><strong>Canonical considerations (how to interpret this evaluation):</strong></div>
        <ul>
          <li><strong>Opinion, not evidence:</strong> This evaluation is narrative feedback only; it is not an audit, certification, benchmark result, or compliance determination.</li>
          <li><strong>Model limitations apply:</strong> LLM outputs may be incomplete or persuasive without being correct. Treat all claims here as non-authoritative until independently verified.</li>
          <li><strong>No endorsement implied:</strong> Mention of OpenAI ChatGPT 5.2 does not imply OpenAI endorsement of this repository or its contents.</li>
          <li><strong>Governance-first labeling:</strong> Use this section only as an example of how organizations can document external opinions without confusing them for verification.</li>
        </ul>
      </div>
    </section>

    <section class="section" id="disclaimer">
      <h2>License and Disclaimers</h2>

      <p class="small">
        <strong>Educational disclaimer:</strong> This material is provided for educational purposes only. It does not constitute investment,
        legal, tax, accounting, compliance, or financial advice. A qualified human professional must review, verify, and approve any use in practice.
      </p>

      <p class="small">
        <strong>Client confidentiality and data hygiene:</strong> Do not paste confidential client information into external model prompts.
        Use redaction/anonymization and “minimum necessary” inputs by default. Document any exception and follow firm policy and applicable law.
      </p>

      <p class="small">
        <strong>Facts are not assumptions:</strong> Outputs must clearly separate facts provided by the user from assumptions and open questions.
        Treat all model-generated content as <em>Not verified</em> until validated by a human.
      </p>

      <p class="small">
        <strong>No autonomous decision authority:</strong> This courseware is designed to teach governed productivity. It must not be used to
        create eligibility rules, automate high-stakes decisions, or replace accountable human supervision.
      </p>

      <p class="small">
        <strong>No fabricated sources or product claims:</strong> Zero tolerance for invented product terms, performance claims, fees, tax consequences,
        or citations. When evidence is missing, the correct output is a verification task list.
      </p>

      <p class="small">
        <strong>Use of generative AI tools (transparency):</strong> Generative AI tools may have been used to
